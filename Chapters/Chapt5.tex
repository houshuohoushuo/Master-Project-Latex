\chapter{Conclusion} 
\label{conclusion}

We implement four CNN models, Small CNN, VGG, VGG-IN, and ResNet. We train these models on the US and PAT datasets, as well as the IDC Breast Cancer dataset and the Cats vs. Dogs dataset. The experimental results show that the performance of these models on the US and PAT datasets is poor. From the model accuracy plots (Fig.\,\ref{fig:acc}), we do not see a consistent improvement of the validation accuracy (except for (G) VGG-IN US). Because of such jumping curves, it would be meaningless to conclude which model performs the best in classifying US and PAT images. The number of samples in the US and PAT datasets is very limited compared to the IDC Breast Cancer dataset, and the Dogs vs. Cats dataset. There are about 1,700 US images and 2,000 PAT images (after data augmentation) from 54 samples, yet the IDC Breast Cancer dataset has about 300,000 images from 162 sample and the Dogs vs. Cats dataset has over 20,000 images. On the IDC Breast Cancer dataset, the Small CNN model and the ResNet model have the best accuracy of 0.89 and 0.88 respectively; VGG-IN is at 0.85. On the Dogs vs. Cats dataset, all three models perform similarly. The accuracy is 0.93 for the Small CNN model and the ResNet Model, 0.92 for the VGG-IN model.

The lack of training samples in the US and PAT datasets could be a major cause of the models' poor performance. The Small CNN model and the ResNet model have the potential to achieve better accuracy on the US and PAT datasets with more training data and perhaps better image quality. The ResNet model is preferable than the other models to be re-trained in the future on the US and PAT datasets (with more samples added), because its loss curves (Fig,\,\ref{fig:loss} (C) (D)) show better performance than the other models'.

The experimental results also show that a deep neural network model, such as the VGG model, may encounter the degradation problem which prevents the network from training. The ResNet model, even though it has almost the same depth as VGG, is able to overcome this problem by introducing shortcuts and match the performance of a shallower model.

\paragraph{Future works}

1. When more US and PAT image data is available, we could re-train the models. We have only considered class B and C. With more data belonging to other classes, we can expand the classification layer to predict more than two classes. In addition, we are expecting to see an improvement in accuracy with more data.

2. In this project, we use 2D CNN models to classify every slice of a 3D image. We can use a 3D CNN model \citep{tran2015learning} to classify a 3D image (a specimen) as a whole. This approach will require more samples in each class, since we will not be able to split image stacks to create more data for each class.